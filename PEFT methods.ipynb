{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e681c51bce93435192f32defccd6f76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d38f373f76e4721962be0c853e70b0d",
              "IPY_MODEL_5a9b9e71095f416e84a89bc6f429b318",
              "IPY_MODEL_28013cab96c44804ac05bfc326efd096"
            ],
            "layout": "IPY_MODEL_e5596b0ab5564f1b90d41c56e8138966"
          }
        },
        "7d38f373f76e4721962be0c853e70b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea32182286d4889bf30254ba89c4d68",
            "placeholder": "​",
            "style": "IPY_MODEL_f0421e85af62487db431afcc36ca21b2",
            "value": "config.json: 100%"
          }
        },
        "5a9b9e71095f416e84a89bc6f429b318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d39e82a61b5541f898a5f62365c0f963",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e98028dc10634132a7da7e39b73b9871",
            "value": 481
          }
        },
        "28013cab96c44804ac05bfc326efd096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719510a7b6584608adafa6ec8f8bfd62",
            "placeholder": "​",
            "style": "IPY_MODEL_c72e9479272c416fb5274c1f51f460a1",
            "value": " 481/481 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "e5596b0ab5564f1b90d41c56e8138966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea32182286d4889bf30254ba89c4d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0421e85af62487db431afcc36ca21b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d39e82a61b5541f898a5f62365c0f963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98028dc10634132a7da7e39b73b9871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "719510a7b6584608adafa6ec8f8bfd62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72e9479272c416fb5274c1f51f460a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "becaa6a5497445d68531cb07105a0620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2bf29040c9a4fa888bda9eebd3c9f40",
              "IPY_MODEL_7dfa902870854cc3bcea78602bd7e814",
              "IPY_MODEL_9a24ea24b30c49249edd7521df2273f5"
            ],
            "layout": "IPY_MODEL_593974955fb34d5e9aef987fca009b43"
          }
        },
        "f2bf29040c9a4fa888bda9eebd3c9f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_216a290acec24497ac03e5bfc0732634",
            "placeholder": "​",
            "style": "IPY_MODEL_52baa8e68d594710b2d2361877359105",
            "value": "model.safetensors: 100%"
          }
        },
        "7dfa902870854cc3bcea78602bd7e814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9ded8536974a8281b1713f0165dfef",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_258c5c3319c449b59144a18c99723590",
            "value": 498818054
          }
        },
        "9a24ea24b30c49249edd7521df2273f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345a31319e2949c7b29fff398b67890a",
            "placeholder": "​",
            "style": "IPY_MODEL_0ec6184f16b64c02844fcc51b54b21cc",
            "value": " 499M/499M [00:05&lt;00:00, 168MB/s]"
          }
        },
        "593974955fb34d5e9aef987fca009b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216a290acec24497ac03e5bfc0732634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52baa8e68d594710b2d2361877359105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb9ded8536974a8281b1713f0165dfef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258c5c3319c449b59144a18c99723590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "345a31319e2949c7b29fff398b67890a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec6184f16b64c02844fcc51b54b21cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e1f9ffa46443ba970bc126ebd58246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac1c9ccb7d314fc9980acd01e313cc3a",
              "IPY_MODEL_bd255724520c44f6b6ab286f66623ce5",
              "IPY_MODEL_2e07cf9ac0414f04a6d74fb8332866dd"
            ],
            "layout": "IPY_MODEL_34675123ac8248d18dc0e26e56180933"
          }
        },
        "ac1c9ccb7d314fc9980acd01e313cc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2cd556e2514ddc86bf2746dd8b70df",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d4b7784b8142f2a8d299fee684880e",
            "value": "Map: 100%"
          }
        },
        "bd255724520c44f6b6ab286f66623ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f62e9480ab9494ab6db58f4b324dbbb",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1de1e66e15b545f284d32ecb65423394",
            "value": 2000
          }
        },
        "2e07cf9ac0414f04a6d74fb8332866dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7d4f247fe645bba7637c481e355505",
            "placeholder": "​",
            "style": "IPY_MODEL_82750585759b498685d57bfefdfd7631",
            "value": " 2000/2000 [00:01&lt;00:00, 1224.46 examples/s]"
          }
        },
        "34675123ac8248d18dc0e26e56180933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2cd556e2514ddc86bf2746dd8b70df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d4b7784b8142f2a8d299fee684880e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f62e9480ab9494ab6db58f4b324dbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de1e66e15b545f284d32ecb65423394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7d4f247fe645bba7637c481e355505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82750585759b498685d57bfefdfd7631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qbRq1uj5WA-p",
        "outputId": "9dd21104-5f32-4087-d094-1898da06bbcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHJjijFTrOrg",
        "outputId": "572d6abb-e028-4fbe-a702-5676daa9f12f",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data prepocessing"
      ],
      "metadata": {
        "id": "4dADg6zH2dN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "\n",
        "train_dataset = dataset[\"train\"].select(range(3000))\n",
        "test_dataset = dataset[\"test\"].select(range(2000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF7VRVY0TIJd",
        "outputId": "10f14122-337e-4e4b-f190-7f7d344bcf3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "\n",
        "train_dataset = dataset[\"train\"].map(tokenize, batched=True)\n",
        "test_dataset = dataset[\"test\"].map(tokenize, batched=True)\n",
        "\n",
        "\n",
        "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "\n",
        "print(train_dataset[0])\n",
        "print(test_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdec693cc7e24143a46d4730d74f7990",
            "3ffd2783332347ecb2ed42f491464301",
            "c0c57cccd0d640fb9d6552ea00e16cc5",
            "38f92fb8a6624fafbbd626ee77b3dc11",
            "78818a8ecfcc43069785fc28ffc7a91f",
            "bcc39e8863c8470ba52b2b3b852e0509",
            "cc16f0918765484a930da847aa262d8e",
            "720ae723f4a148ea8c82e0a4f8ff62a3",
            "67b6b9c58d35441f8c5f34fae0ea883e",
            "d776335ce35a4547bbdcde06ca1062a0",
            "9279fa27071843ca9882dfa19776841e",
            "9b8bc7cbbb754a69a72af81122d3cc91",
            "35805e4faf244d7985713c2475683b21",
            "c7d13f28b6c54190ab21df7a47efdba9",
            "f20983bc91d94753a041d43bd2662997",
            "d283fd6d03da478ca80d1da4775d6d22",
            "80e5a3c884294070afb72ded09de955a",
            "d84119ca1f9e4812a49bb81507bbe17c",
            "bc4e2e57b3ed42e79a17f83f334f5529",
            "aab0692ebb084aec866ee891989e5045",
            "265a1c27a9e84bfe86699efc7a992bc1",
            "63a08ef9013b41c1b250f06f84d52a75",
            "7115537e076c4b51b565e6657a2a5644",
            "5e04c522b82644418ee1f49acde440bb",
            "40914256f8ba432f84b9e7134f4aefeb",
            "d0bef23138d24043b35ffa6b84a99777",
            "5bb1fcc0b6c44c37a37ea4f8c42db4d3",
            "d8814662d58a4ba59bb84072a3d0c2f8",
            "50427fbf8a5c4a21b9d19e495c0f294d",
            "b66cc31c78a449cf8547e9a767e48fac",
            "cd966cc1051f44a2b6259a416690444c",
            "25bf70d7434e4331b3c25d928490e49c",
            "33393d45080b4771836c1b4db6b8541a",
            "a3b1f66213fe41c7b895d957027f8632",
            "8f19710154e042ddb7e67020057a47b1",
            "b45b93eda8fe4a55a607845d57ec1f26",
            "4de419435dfc4e77add107ff390f7e6d",
            "53014682015e4b23a8df7426bba77797",
            "7cc48ba271e74846859dc0ad5fc9d0b4",
            "0d386e470df14ddca21d263013095764",
            "be7edd271e3044ca910b8da4fc59e0eb",
            "9d842ac5ffa841969fdab871826094a1",
            "ca65469ab75a447d9c73deed20d2f2c1",
            "b118426365ba4e8c8267ea61714a46f0",
            "bddbf7674efc4317ad248f331ae9f98a",
            "94c9bb3e0acb4fb49506d09270e705c5",
            "0e5c510c99e847439c62f0066528bfb6",
            "518e35d6c4514d1ea34e8d9b8cddbbee",
            "20f9dcf0f6364787857fd6ef4b6768a4",
            "e76cfa818e7c41f68001297b7835b9e5",
            "5d820d83ff644048aac4c530ab33cd2d",
            "f945d878704842bfb904ae6ede82b110",
            "affa91bfbffa481e9541d38afa780a8e",
            "5bab7740698c45ea927ef4d9d3f91e4e",
            "e224d829223c45aaa3e703371cc3c7e0",
            "ea39db41cc3c4ace83a7c76ebf065414",
            "1ebf257cb70d451e9650ac5c68e576d6",
            "1c986cd1bc934287a7b6ec0dec674ef1",
            "fbcd066b7fc246ff9375fd6be1868ef7",
            "b92b8475d9b84af79c1251ebf4053c42",
            "f8a22105ef564ceb8696abde698ca5e3",
            "94ba25e676204750a6e8d22a6494af0d",
            "f2e818887a4649f29d618e471c2a45f6",
            "325130fe31344067b3b83a2ec04685ef",
            "2cf88650d3be415bb2898de998ac872b",
            "c2830e0c88294aa786fea9569096ae01",
            "027cae6207254c4b90406a8c1196adb6",
            "bca182ebb3024401bf92cb7b78e382a0",
            "13d77923f3644a74b6b538f03af759e2",
            "25856a570ab6412d9a8bfc815e6b1aad",
            "6739ff12c1a942d69dcaf9d28099563d",
            "f4c526fe9a854e00b755b7c1a96f8531",
            "277a0fc3134c4735ba9e1679a45569b5",
            "a8d75ee980414024ba374323c43f8b1c",
            "21d17e2a8e10411babd5202c3910496a",
            "d9fedef58784473fa83864b00fe55d93",
            "4b87e2e9aa2f4e6f90863a234bcc6177",
            "23f38cfa99914fbea1906f092de1010d",
            "58287c8fafcf4f54af2ef366356484da",
            "3732374bd76744d59ca557be4ca75837",
            "d95623a6ce7f41cd88edcbf2b6898b52",
            "444d0cc47abc4c4eacef6003f6344916",
            "b8914c5d464f46859a4137631854692b",
            "e8c909f9d28f421e835338267b3885c4",
            "7edf684c849147ffb33c1616725b23d1",
            "e647d36ede4342ef8d2cdc8458f734d9",
            "6ec87287844943019a1f5a55cd656a7a",
            "66312a1ae2d44fe9855e9c7a03fb9adb",
            "cca6606797684f5980f0a6d67c7242a7",
            "6ef212f8d5f94c7a8b56fca07bfd89e8",
            "aeff6e1686ae4acd9e6d60fd10728204",
            "5bc0ea2dd3b849b1b52d242f01d98b99",
            "49c01a10b59547869a13daf870c71562",
            "8acf62b9f260434bbcde9bb3df6835e2",
            "ab5bc401656a4a848640e197bb3e8049",
            "9980b298d29042969c3d20e235363d1e",
            "0d1545d30ea74dfc8c4df39f853ed8e5",
            "bc1ccf79586642c2a8e4471a61889ae0",
            "372c602345294a05a7e5ee6ddadf1fac",
            "06f617f541034a12834c5a2ae225bf9c",
            "fec932cfb8e948db864eb15c52fbcb99",
            "39437025d3244cb088b27aacc26c93df",
            "361444f2e6394b4aa1a3586abfe83c8b",
            "03f6a3b9264b47c1aaf7f28bf21f03de",
            "831bfb3fe7e14661b186dfe19eac5ce4",
            "9e9f17dbdb1c490191129ecb3ca9742e",
            "bb0965cfd2eb40c1a75314aab8701c6e",
            "4c15f982ef0c49aa90475a691e75bd26",
            "e1026de839244fe69a849544a2f8e7e6",
            "495027a4c8db491f82146767c2828df5",
            "bf343096046e4c1a8fa4483a9412b8e0",
            "5e34eee0ef2e429d88b5cd59f16c2a5b",
            "22732039a7824f3aaf89b7e16e5d4796",
            "72a81c5e185c4d5d96233f3bc4eb53d4",
            "16091684504045aaafa0bc99f18e53fb",
            "c2a08e858ef34c2c946c10661cdf0b18",
            "6f713aa2f4264e0491cae4323300392b",
            "561b0e31e2124621b9cba105b094077e",
            "ea257436f70543b48b6364220a8d2672",
            "22291a1aa92f470a9ccfe6f62e131355",
            "b0964bd2323c4339ad76a88a918e453f",
            "ed3ddc70723f40b6867e159fef4c8869",
            "1107bd2786924438ac611a86104a0f9e",
            "4151f4c1725d4bb6a68a933728490aa1",
            "c906293e7c364a11a97dc6ebac998216",
            "260f7701e4a44e7c8f6566633a352901",
            "c41fd312034f4017a0478dabac078ae1",
            "947ff30170c141b48ab239b5d195a350",
            "5a7cf3b9af354aa787705d38eb084dc8",
            "279bc5d2d27142f0a13eb6d9995a44c1",
            "efa816b215804f5ebe83b6094d162634",
            "dfe8a15b20a14d718632a5f767c15f3d",
            "90e89cf5292b43de8b8d6cdd2f7c60c6",
            "818c11ec79e1432ea04c45d91bed780f",
            "b5d7c39ddae241adb0857b9fc9274606",
            "ffbe9e1da97843758e47a4fd577ce727",
            "5c8c97bf1ddf426f876e0b6058446990",
            "b45b2c46826b4256b1e9f80761f98462",
            "d86e60b1f9bf4318a83e5d599f091fbc",
            "f45795c8b1b04e9db065ecd6b3ef563d",
            "b1bacfcefffa4c199acacdbc533a6eba",
            "742455528a0142efacc4d67ed6bc6fa2",
            "af79764f888440eb89c767cd8b1f1f76"
          ]
        },
        "id": "midPK2TRLVWB",
        "outputId": "7b6114e2-9a9a-4361-fe76-c97dc6bdd575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdec693cc7e24143a46d4730d74f7990"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b8bc7cbbb754a69a72af81122d3cc91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7115537e076c4b51b565e6657a2a5644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3b1f66213fe41c7b895d957027f8632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bddbf7674efc4317ad248f331ae9f98a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea39db41cc3c4ace83a7c76ebf065414"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "027cae6207254c4b90406a8c1196adb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23f38cfa99914fbea1906f092de1010d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cca6606797684f5980f0a6d67c7242a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f617f541034a12834c5a2ae225bf9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf343096046e4c1a8fa4483a9412b8e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed3ddc70723f40b6867e159fef4c8869"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90e89cf5292b43de8b8d6cdd2f7c60c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': tensor(0), 'input_ids': tensor([    0,   100, 16425,    38,  3326,   230, 42338, 18024,    12,   975,\n",
            "        25322,  4581,    31,   127,   569,  1400,   142,     9,    70,     5,\n",
            "         6170,    14,  7501,    24,    77,    24,    21,    78,   703,    11,\n",
            "        13025,     4,    38,    67,  1317,    14,    23,    78,    24,    21,\n",
            "         5942,    30,   121,     4,   104,     4, 10102,   114,    24,   655,\n",
            "         1381,     7,  2914,    42,   247,     6,  3891,   145,    10,  2378,\n",
            "            9,  3541,  1687,    22, 10800, 34689,   113,    38,   269,    56,\n",
            "            7,   192,    42,    13,  2185, 49069,  3809,  1589, 49007,  3809,\n",
            "        48709,   133,  6197,    16, 14889,   198,    10,   664,  9004,  4149,\n",
            "         1294,  1440, 27450,    54,  1072,     7,  1532,   960,    79,    64,\n",
            "           59,   301,     4,    96,  1989,    79,  1072,     7,  1056,    69,\n",
            "        39879,  2485,     7,   442,   103,  2345,     9,  6717,    15,    99,\n",
            "            5,   674, 25517,   242,   802,    59,  1402,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])}\n",
            "{'label': tensor(0), 'input_ids': tensor([    0,   100,   657, 19974,    12,  9169,     8,   524,  2882,     7,\n",
            "          342,    62,    19,    10,   319,     4, 22640,    12,  9169,  4133,\n",
            "           73,  2915,    32,  2333,   223, 11856,     6,   223,    12,  3340,\n",
            "        19954,  1070,     8, 32085,     4,    38,  1381,     7,   101,    42,\n",
            "            6,    38,   269,   222,     6,    53,    24,    16,     7,   205,\n",
            "         1012, 19974,    12,  9169,    25, 41170,   195,    16,     7,  2141,\n",
            "        20351,    36,   627,  1461,   322,   208, 10758, 22115, 34680,     6,\n",
            "         6162, 25081,  3880,     6,  1690,   718,  5357, 25730,  3663,     6,\n",
            "        33354,    14,   630,    75,   914,     5,  3618,     6,     8, 32020,\n",
            "           65,    12, 23944,  3768,  1395,    28,  6647,    19,    10,   128,\n",
            "        43428,    12,  9169,   108,  2749,     4,    36,   100,   437,   686,\n",
            "           89,    32,   167,     9,    47,    66,    89,    54,   206, 41170,\n",
            "          195,    16,   205, 19974,    12,  9169,  1012,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "# Load tokenizer for roberta-base\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
      ],
      "metadata": {
        "id": "qIUxh3ZCTLC3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "# Tokenize both train and test sets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "SqERJABTTQf-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ],
      "metadata": {
        "id": "C8jV_Xg4TVx_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lhYJmufkrDF9",
        "outputId": "eb7e7f01-88d5-4c04-d086-dcb300248bb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dTEr5-FrYNmI",
        "outputId": "c853ba63-eac8-4b16-bd3b-7fcfc0e69b3d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full finetune"
      ],
      "metadata": {
        "id": "2iKnfk602jhC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NW_xJZ6pmtPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Load model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "# Accuracy metric\n",
        "def compute_metrics(p):\n",
        "    preds, labels = p\n",
        "    preds = torch.tensor(preds)\n",
        "    labels = torch.tensor(labels)\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    return {\"accuracy\": accuracy_score(labels.numpy(), preds.numpy())}\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Training\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "end = time.time()\n",
        "print(f\"Training time: {end - start:.2f} seconds\")\n",
        "\n",
        "# Evaluation\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Accuracy: {eval_results['eval_accuracy'] * 100:.2f}%\")\n",
        "\n",
        "# Model size\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "gpu_mem = torch.cuda.memory_allocated() / 1024**2\n",
        "print(f\"Trainable parameters: {params}\")\n",
        "print(f\"GPU memory used: {gpu_mem:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f6a32bb-7b47-4154-8631-59d520ad8ad9",
        "id": "E5mu0dgYmtiB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ml217691\u001b[0m (\u001b[33mrabiya\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_134323-hhybz7i2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabiya/huggingface/runs/hhybz7i2' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rabiya/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rabiya/huggingface' target=\"_blank\">https://wandb.ai/rabiya/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rabiya/huggingface/runs/hhybz7i2' target=\"_blank\">https://wandb.ai/rabiya/huggingface/runs/hhybz7i2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9375/9375 37:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.738900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.701400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.611600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.526500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.549500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.590200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.516300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.574500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.569600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.618500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.487000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.387600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.577300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.537200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.426600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.471400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.463200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.272200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.695400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.526000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.425600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.375500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.914300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.698700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.495700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.539400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.519000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.567400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.495100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.596600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.606000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.523000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.730600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.626200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.569300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.522700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.439800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.569700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.503600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.487600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.641200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.335200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.748800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.559700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.747000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.472700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.515700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.913500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.949500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.734000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.827700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.619400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.581500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.481400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.451700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.382400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.504100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.432200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.637400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.529900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.447100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.573400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.416700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.385500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.406500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.621500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.515700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.417700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.518800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.407200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.814600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.418600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.395600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.411400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.325800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.328000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.564000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.493400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.481100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.296600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.495400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.482500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.511000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.399900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.425300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.497500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.313700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.349700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.516600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.602900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.509400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.499500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.497100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.391800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.487200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.561300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.409400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.517600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.474200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.539500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.650500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.581300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.497000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.498400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.309100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.472400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.463800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.260700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.367500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.662400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.549700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.387300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.459100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.520400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.338200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.398800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.667200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.493100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.596100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.379200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.507200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.255500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.503400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.397300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.417200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.622500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.511600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.584500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.345900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.434900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.412600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.371800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.344000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.368900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.353900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.392300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.338000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.333200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.475500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.486500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.510500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.486800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.266200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.466800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.421500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.464800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.347500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.387900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.394300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.489700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.366700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.339500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.326700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.308700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.158300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.384300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.447300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.414200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.274000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>0.398200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>0.515800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.291700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.335000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>0.411300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>0.280500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>0.433400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>0.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.463500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>0.384800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>0.368500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>0.408100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.513200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.347800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>0.282200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>0.338900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>0.410400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.516700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>0.489400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>0.448100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.450500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>0.392000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.576400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>0.601100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>0.448900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>0.555700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.355000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.468800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>0.724200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.328700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>0.368500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.517900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>0.357800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>0.364600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>0.361400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>0.516600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.274600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>0.476000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.427900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>0.356800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>0.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.525800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>0.240300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>0.608700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>0.462900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.466800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>0.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>0.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.449300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>0.431900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.452900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>0.527600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>0.512900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>0.283800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>0.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.305400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>0.458200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2670</td>\n",
              "      <td>0.566700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2680</td>\n",
              "      <td>0.439000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2690</td>\n",
              "      <td>0.507800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.543800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2710</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>0.410100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2730</td>\n",
              "      <td>0.386500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2740</td>\n",
              "      <td>0.525400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.315500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2760</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2770</td>\n",
              "      <td>0.547900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2780</td>\n",
              "      <td>0.349800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2790</td>\n",
              "      <td>0.295600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2810</td>\n",
              "      <td>0.552200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2820</td>\n",
              "      <td>0.524600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2830</td>\n",
              "      <td>0.514900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2840</td>\n",
              "      <td>0.419800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.356700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2860</td>\n",
              "      <td>0.409600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2870</td>\n",
              "      <td>0.342500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2880</td>\n",
              "      <td>0.649400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2890</td>\n",
              "      <td>0.302300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.417900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2910</td>\n",
              "      <td>0.352100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2920</td>\n",
              "      <td>0.342400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2930</td>\n",
              "      <td>0.468900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2940</td>\n",
              "      <td>0.331100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.282200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2960</td>\n",
              "      <td>0.371200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2970</td>\n",
              "      <td>0.324600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2980</td>\n",
              "      <td>0.388000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2990</td>\n",
              "      <td>0.359500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.432400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3010</td>\n",
              "      <td>0.533300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3020</td>\n",
              "      <td>0.352500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3030</td>\n",
              "      <td>0.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3040</td>\n",
              "      <td>0.347000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.687200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>0.314100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3070</td>\n",
              "      <td>0.448400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3080</td>\n",
              "      <td>0.556400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3090</td>\n",
              "      <td>0.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3110</td>\n",
              "      <td>0.473300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3120</td>\n",
              "      <td>0.293900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3130</td>\n",
              "      <td>0.397500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3140</td>\n",
              "      <td>0.491100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.452700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3160</td>\n",
              "      <td>0.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3170</td>\n",
              "      <td>0.434200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3180</td>\n",
              "      <td>0.395300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3190</td>\n",
              "      <td>0.294200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.490200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3210</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3220</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3230</td>\n",
              "      <td>0.188200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3240</td>\n",
              "      <td>0.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.491800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3260</td>\n",
              "      <td>0.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3270</td>\n",
              "      <td>0.421400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3280</td>\n",
              "      <td>0.751100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3290</td>\n",
              "      <td>0.445100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.293400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3310</td>\n",
              "      <td>0.284200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3320</td>\n",
              "      <td>0.339200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3330</td>\n",
              "      <td>0.512700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3340</td>\n",
              "      <td>0.440300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.373400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3360</td>\n",
              "      <td>0.496700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3370</td>\n",
              "      <td>0.279100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3380</td>\n",
              "      <td>0.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3390</td>\n",
              "      <td>0.431400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3410</td>\n",
              "      <td>0.529800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3420</td>\n",
              "      <td>0.434400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3430</td>\n",
              "      <td>0.336300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3440</td>\n",
              "      <td>0.351300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.307200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3460</td>\n",
              "      <td>0.292000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3470</td>\n",
              "      <td>0.295300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3480</td>\n",
              "      <td>0.458400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3490</td>\n",
              "      <td>0.561400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.649900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3510</td>\n",
              "      <td>0.326100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3520</td>\n",
              "      <td>0.410600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3530</td>\n",
              "      <td>0.235700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3540</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3560</td>\n",
              "      <td>0.420500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3570</td>\n",
              "      <td>0.418600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3580</td>\n",
              "      <td>0.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3590</td>\n",
              "      <td>0.471100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.333700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3610</td>\n",
              "      <td>0.357900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3620</td>\n",
              "      <td>0.436400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3630</td>\n",
              "      <td>0.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3640</td>\n",
              "      <td>0.245400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.394800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3660</td>\n",
              "      <td>0.755700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3670</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3680</td>\n",
              "      <td>0.459700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3690</td>\n",
              "      <td>0.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3710</td>\n",
              "      <td>0.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3720</td>\n",
              "      <td>0.621100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3730</td>\n",
              "      <td>0.309800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3740</td>\n",
              "      <td>0.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.406400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3760</td>\n",
              "      <td>0.251300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3770</td>\n",
              "      <td>0.437200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3780</td>\n",
              "      <td>0.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3790</td>\n",
              "      <td>0.523500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.465700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3810</td>\n",
              "      <td>0.391100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3820</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3830</td>\n",
              "      <td>0.423500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3840</td>\n",
              "      <td>0.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.364900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3860</td>\n",
              "      <td>0.735900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3870</td>\n",
              "      <td>0.352900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3880</td>\n",
              "      <td>0.661100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3890</td>\n",
              "      <td>0.276800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3910</td>\n",
              "      <td>0.323700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3920</td>\n",
              "      <td>0.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3930</td>\n",
              "      <td>0.270200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3940</td>\n",
              "      <td>0.282200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.219300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3960</td>\n",
              "      <td>0.367200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3970</td>\n",
              "      <td>0.276300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3980</td>\n",
              "      <td>0.512400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3990</td>\n",
              "      <td>0.477800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.213800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4010</td>\n",
              "      <td>0.438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4020</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4030</td>\n",
              "      <td>0.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4040</td>\n",
              "      <td>0.262800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.363800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4060</td>\n",
              "      <td>0.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4070</td>\n",
              "      <td>0.321100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4080</td>\n",
              "      <td>0.450800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4090</td>\n",
              "      <td>0.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.539000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4110</td>\n",
              "      <td>0.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4120</td>\n",
              "      <td>0.379300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4130</td>\n",
              "      <td>0.470300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4140</td>\n",
              "      <td>0.379500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.204000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4160</td>\n",
              "      <td>0.345500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4170</td>\n",
              "      <td>0.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4180</td>\n",
              "      <td>0.454000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4190</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.272300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4210</td>\n",
              "      <td>0.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4220</td>\n",
              "      <td>0.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4230</td>\n",
              "      <td>0.434600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4240</td>\n",
              "      <td>0.270300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.390800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4260</td>\n",
              "      <td>0.279500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4270</td>\n",
              "      <td>0.501200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4280</td>\n",
              "      <td>0.655300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4290</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.278900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4310</td>\n",
              "      <td>0.312200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4320</td>\n",
              "      <td>0.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4330</td>\n",
              "      <td>0.340400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4340</td>\n",
              "      <td>0.471400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4360</td>\n",
              "      <td>0.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4370</td>\n",
              "      <td>0.312900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4380</td>\n",
              "      <td>0.342500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4390</td>\n",
              "      <td>0.405700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.413500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4410</td>\n",
              "      <td>0.201400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4420</td>\n",
              "      <td>0.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4430</td>\n",
              "      <td>0.421200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4440</td>\n",
              "      <td>0.295600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.383000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4460</td>\n",
              "      <td>0.494800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4470</td>\n",
              "      <td>0.260700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4480</td>\n",
              "      <td>0.212300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4490</td>\n",
              "      <td>0.382700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.497100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4510</td>\n",
              "      <td>0.453800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4520</td>\n",
              "      <td>0.319200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4530</td>\n",
              "      <td>0.464700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4540</td>\n",
              "      <td>0.311900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4560</td>\n",
              "      <td>0.545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4570</td>\n",
              "      <td>0.431500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4580</td>\n",
              "      <td>0.561100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4590</td>\n",
              "      <td>0.392600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.374200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4610</td>\n",
              "      <td>0.408400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4620</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4630</td>\n",
              "      <td>0.439700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4640</td>\n",
              "      <td>0.382700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.350200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4660</td>\n",
              "      <td>0.512600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4670</td>\n",
              "      <td>0.505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4680</td>\n",
              "      <td>0.286200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4690</td>\n",
              "      <td>0.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.356700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4710</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4720</td>\n",
              "      <td>0.477200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4730</td>\n",
              "      <td>0.370300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4740</td>\n",
              "      <td>0.410400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.660600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4760</td>\n",
              "      <td>0.282800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4770</td>\n",
              "      <td>0.436600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4780</td>\n",
              "      <td>0.306000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4790</td>\n",
              "      <td>0.280100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4810</td>\n",
              "      <td>0.634200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4820</td>\n",
              "      <td>0.486900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4830</td>\n",
              "      <td>0.361800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4840</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4860</td>\n",
              "      <td>0.207200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4870</td>\n",
              "      <td>0.272900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4880</td>\n",
              "      <td>0.261800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4890</td>\n",
              "      <td>0.344200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4910</td>\n",
              "      <td>0.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4920</td>\n",
              "      <td>0.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4930</td>\n",
              "      <td>0.264700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4940</td>\n",
              "      <td>0.251900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>0.216100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4960</td>\n",
              "      <td>0.314000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4970</td>\n",
              "      <td>0.429500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4980</td>\n",
              "      <td>0.449000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4990</td>\n",
              "      <td>0.662700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.477000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5010</td>\n",
              "      <td>0.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5020</td>\n",
              "      <td>0.284800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5030</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5040</td>\n",
              "      <td>0.496200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>0.413700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5060</td>\n",
              "      <td>0.336400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5070</td>\n",
              "      <td>0.294700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5080</td>\n",
              "      <td>0.434700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5090</td>\n",
              "      <td>0.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.436100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5110</td>\n",
              "      <td>0.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5120</td>\n",
              "      <td>0.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5130</td>\n",
              "      <td>0.406900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5140</td>\n",
              "      <td>0.396600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>0.336400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5160</td>\n",
              "      <td>0.217200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5170</td>\n",
              "      <td>0.331600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5180</td>\n",
              "      <td>0.336900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5190</td>\n",
              "      <td>0.253300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.486900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5210</td>\n",
              "      <td>0.423700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5220</td>\n",
              "      <td>0.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5230</td>\n",
              "      <td>0.425200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5240</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>0.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5260</td>\n",
              "      <td>0.293700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5270</td>\n",
              "      <td>0.497000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5280</td>\n",
              "      <td>0.439000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5290</td>\n",
              "      <td>0.451100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5310</td>\n",
              "      <td>0.363000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5320</td>\n",
              "      <td>0.390600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5330</td>\n",
              "      <td>0.434900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5340</td>\n",
              "      <td>0.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>0.378500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5360</td>\n",
              "      <td>0.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5370</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5380</td>\n",
              "      <td>0.305500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5390</td>\n",
              "      <td>0.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.431000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5410</td>\n",
              "      <td>0.300100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5420</td>\n",
              "      <td>0.357900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5430</td>\n",
              "      <td>0.678300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5440</td>\n",
              "      <td>0.286000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>0.307700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5460</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5470</td>\n",
              "      <td>0.294100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5480</td>\n",
              "      <td>0.319600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5490</td>\n",
              "      <td>0.556400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5510</td>\n",
              "      <td>0.308000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5520</td>\n",
              "      <td>0.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5530</td>\n",
              "      <td>0.261900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5540</td>\n",
              "      <td>0.234300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>0.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5560</td>\n",
              "      <td>0.411000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5570</td>\n",
              "      <td>0.231900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5580</td>\n",
              "      <td>0.298300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5590</td>\n",
              "      <td>0.276600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.362700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5610</td>\n",
              "      <td>0.576400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5620</td>\n",
              "      <td>0.421400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5630</td>\n",
              "      <td>0.494300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5640</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>0.369800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5660</td>\n",
              "      <td>0.391800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5670</td>\n",
              "      <td>0.339800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5680</td>\n",
              "      <td>0.255500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5690</td>\n",
              "      <td>0.195600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.458800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5710</td>\n",
              "      <td>0.414300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5720</td>\n",
              "      <td>0.235800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5730</td>\n",
              "      <td>0.294500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5740</td>\n",
              "      <td>0.419700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>0.375300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5760</td>\n",
              "      <td>0.356100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5770</td>\n",
              "      <td>0.346800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5780</td>\n",
              "      <td>0.559000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5790</td>\n",
              "      <td>0.292600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.446400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5810</td>\n",
              "      <td>0.506500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5820</td>\n",
              "      <td>0.512300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5830</td>\n",
              "      <td>0.353800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5840</td>\n",
              "      <td>0.175300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>0.515000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5860</td>\n",
              "      <td>0.488700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5870</td>\n",
              "      <td>0.372500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5880</td>\n",
              "      <td>0.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5890</td>\n",
              "      <td>0.577100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.236400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5910</td>\n",
              "      <td>0.391900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5920</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5930</td>\n",
              "      <td>0.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5940</td>\n",
              "      <td>0.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5960</td>\n",
              "      <td>0.502100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5970</td>\n",
              "      <td>0.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5980</td>\n",
              "      <td>0.203400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5990</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.309000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6010</td>\n",
              "      <td>0.384400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6020</td>\n",
              "      <td>0.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6030</td>\n",
              "      <td>0.378600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6040</td>\n",
              "      <td>0.177200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>0.407600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6060</td>\n",
              "      <td>0.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6070</td>\n",
              "      <td>0.251700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6080</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6090</td>\n",
              "      <td>0.452300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.486900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6110</td>\n",
              "      <td>0.247700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6120</td>\n",
              "      <td>0.353500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6130</td>\n",
              "      <td>0.322800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6140</td>\n",
              "      <td>0.293900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>0.320800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6160</td>\n",
              "      <td>0.226400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6170</td>\n",
              "      <td>0.285000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6180</td>\n",
              "      <td>0.158600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6190</td>\n",
              "      <td>0.250200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6210</td>\n",
              "      <td>0.250600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6220</td>\n",
              "      <td>0.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6230</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6240</td>\n",
              "      <td>0.486000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6260</td>\n",
              "      <td>0.279600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6270</td>\n",
              "      <td>0.165600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6280</td>\n",
              "      <td>0.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6290</td>\n",
              "      <td>0.108900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.209200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6310</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6320</td>\n",
              "      <td>0.299700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6330</td>\n",
              "      <td>0.267000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6340</td>\n",
              "      <td>0.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>0.376900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6360</td>\n",
              "      <td>0.175600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6370</td>\n",
              "      <td>0.218200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6380</td>\n",
              "      <td>0.224300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6390</td>\n",
              "      <td>0.355200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6410</td>\n",
              "      <td>0.424200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6420</td>\n",
              "      <td>0.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6430</td>\n",
              "      <td>0.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6440</td>\n",
              "      <td>0.285900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6460</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6470</td>\n",
              "      <td>0.266300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6480</td>\n",
              "      <td>0.254800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6490</td>\n",
              "      <td>0.328300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.224900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6510</td>\n",
              "      <td>0.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6520</td>\n",
              "      <td>0.357600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6530</td>\n",
              "      <td>0.331800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6540</td>\n",
              "      <td>0.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>0.349600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6560</td>\n",
              "      <td>0.192500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6570</td>\n",
              "      <td>0.443600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6580</td>\n",
              "      <td>0.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6590</td>\n",
              "      <td>0.317400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.306000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6610</td>\n",
              "      <td>0.443300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6620</td>\n",
              "      <td>0.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6630</td>\n",
              "      <td>0.108400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6640</td>\n",
              "      <td>0.457300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>0.343400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6660</td>\n",
              "      <td>0.369500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6670</td>\n",
              "      <td>0.427000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6680</td>\n",
              "      <td>0.469000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6690</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.194300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6710</td>\n",
              "      <td>0.345000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6720</td>\n",
              "      <td>0.340700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6730</td>\n",
              "      <td>0.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6740</td>\n",
              "      <td>0.268700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>0.332000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6760</td>\n",
              "      <td>0.487300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6770</td>\n",
              "      <td>0.405400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6780</td>\n",
              "      <td>0.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6790</td>\n",
              "      <td>0.318300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.328200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6810</td>\n",
              "      <td>0.205700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6820</td>\n",
              "      <td>0.395200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6830</td>\n",
              "      <td>0.323100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6840</td>\n",
              "      <td>0.317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>0.232900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6860</td>\n",
              "      <td>0.389400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6870</td>\n",
              "      <td>0.288900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6880</td>\n",
              "      <td>0.158700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6890</td>\n",
              "      <td>0.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.363100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6910</td>\n",
              "      <td>0.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6920</td>\n",
              "      <td>0.272900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6930</td>\n",
              "      <td>0.251700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6940</td>\n",
              "      <td>0.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>0.053400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6960</td>\n",
              "      <td>0.504500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6970</td>\n",
              "      <td>0.150100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6980</td>\n",
              "      <td>0.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6990</td>\n",
              "      <td>0.419300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.294400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7010</td>\n",
              "      <td>0.443800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7020</td>\n",
              "      <td>0.652000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7030</td>\n",
              "      <td>0.235300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7040</td>\n",
              "      <td>0.208700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>0.501600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7060</td>\n",
              "      <td>0.327900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7070</td>\n",
              "      <td>0.196200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7080</td>\n",
              "      <td>0.385600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7090</td>\n",
              "      <td>0.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.218300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7110</td>\n",
              "      <td>0.374200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7120</td>\n",
              "      <td>0.373700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7130</td>\n",
              "      <td>0.310300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7140</td>\n",
              "      <td>0.315100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7160</td>\n",
              "      <td>0.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7170</td>\n",
              "      <td>0.433000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7180</td>\n",
              "      <td>0.485400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7190</td>\n",
              "      <td>0.289200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.444600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7210</td>\n",
              "      <td>0.298000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7220</td>\n",
              "      <td>0.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7230</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7240</td>\n",
              "      <td>0.265200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>0.333200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7260</td>\n",
              "      <td>0.552700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7270</td>\n",
              "      <td>0.511900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7280</td>\n",
              "      <td>0.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7290</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7310</td>\n",
              "      <td>0.274800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7320</td>\n",
              "      <td>0.236700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7330</td>\n",
              "      <td>0.203800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7340</td>\n",
              "      <td>0.200800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>0.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7360</td>\n",
              "      <td>0.283400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7370</td>\n",
              "      <td>0.236600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7380</td>\n",
              "      <td>0.089700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7390</td>\n",
              "      <td>0.399100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.231400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7410</td>\n",
              "      <td>0.313300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7420</td>\n",
              "      <td>0.281800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7430</td>\n",
              "      <td>0.192600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7440</td>\n",
              "      <td>0.246500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>0.307600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7460</td>\n",
              "      <td>0.188400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7470</td>\n",
              "      <td>0.182800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7480</td>\n",
              "      <td>0.128600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7490</td>\n",
              "      <td>0.404100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.353800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7510</td>\n",
              "      <td>0.228800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7520</td>\n",
              "      <td>0.369700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7530</td>\n",
              "      <td>0.235700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7540</td>\n",
              "      <td>0.335700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>0.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7560</td>\n",
              "      <td>0.322700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7570</td>\n",
              "      <td>0.106100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7580</td>\n",
              "      <td>0.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7590</td>\n",
              "      <td>0.404500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.361200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7610</td>\n",
              "      <td>0.258200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7620</td>\n",
              "      <td>0.353300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7630</td>\n",
              "      <td>0.228100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7640</td>\n",
              "      <td>0.205000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>0.399400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7660</td>\n",
              "      <td>0.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7670</td>\n",
              "      <td>0.226700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7680</td>\n",
              "      <td>0.303900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7690</td>\n",
              "      <td>0.571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.364400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7710</td>\n",
              "      <td>0.250400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7720</td>\n",
              "      <td>0.216400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7730</td>\n",
              "      <td>0.256200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7740</td>\n",
              "      <td>0.272600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>0.353500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7760</td>\n",
              "      <td>0.278300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7770</td>\n",
              "      <td>0.363800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7780</td>\n",
              "      <td>0.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7790</td>\n",
              "      <td>0.136900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.299500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7810</td>\n",
              "      <td>0.451700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7820</td>\n",
              "      <td>0.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7830</td>\n",
              "      <td>0.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7840</td>\n",
              "      <td>0.244300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>0.357300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7860</td>\n",
              "      <td>0.251400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7870</td>\n",
              "      <td>0.518400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7880</td>\n",
              "      <td>0.189000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7890</td>\n",
              "      <td>0.217500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.294200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7910</td>\n",
              "      <td>0.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7920</td>\n",
              "      <td>0.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7930</td>\n",
              "      <td>0.382400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7940</td>\n",
              "      <td>0.291300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>0.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7960</td>\n",
              "      <td>0.147600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7970</td>\n",
              "      <td>0.383300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7980</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7990</td>\n",
              "      <td>0.088700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.368800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8010</td>\n",
              "      <td>0.351700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8020</td>\n",
              "      <td>0.190700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8030</td>\n",
              "      <td>0.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8040</td>\n",
              "      <td>0.416600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>0.350500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8060</td>\n",
              "      <td>0.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8070</td>\n",
              "      <td>0.398000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8080</td>\n",
              "      <td>0.193400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8090</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.151600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8110</td>\n",
              "      <td>0.246100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8120</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8130</td>\n",
              "      <td>0.438300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8140</td>\n",
              "      <td>0.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8160</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8170</td>\n",
              "      <td>0.225300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8180</td>\n",
              "      <td>0.282800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8190</td>\n",
              "      <td>0.490600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8210</td>\n",
              "      <td>0.287400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8220</td>\n",
              "      <td>0.316900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8230</td>\n",
              "      <td>0.185700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8240</td>\n",
              "      <td>0.406100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>0.132700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8260</td>\n",
              "      <td>0.144600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8270</td>\n",
              "      <td>0.217100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8280</td>\n",
              "      <td>0.239300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8290</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.393700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8310</td>\n",
              "      <td>0.279200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8320</td>\n",
              "      <td>0.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8330</td>\n",
              "      <td>0.223200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8340</td>\n",
              "      <td>0.588400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>0.318100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8360</td>\n",
              "      <td>0.252300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8370</td>\n",
              "      <td>0.251100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8380</td>\n",
              "      <td>0.561900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8390</td>\n",
              "      <td>0.389600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.440200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8410</td>\n",
              "      <td>0.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8420</td>\n",
              "      <td>0.251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8430</td>\n",
              "      <td>0.318700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8440</td>\n",
              "      <td>0.207600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>0.145800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8460</td>\n",
              "      <td>0.240900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8470</td>\n",
              "      <td>0.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8480</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8490</td>\n",
              "      <td>0.312900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.343900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8510</td>\n",
              "      <td>0.325300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8520</td>\n",
              "      <td>0.237000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8530</td>\n",
              "      <td>0.318900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8540</td>\n",
              "      <td>0.190700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>0.379300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8560</td>\n",
              "      <td>0.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8570</td>\n",
              "      <td>0.260800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8580</td>\n",
              "      <td>0.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8590</td>\n",
              "      <td>0.323100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.305400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8610</td>\n",
              "      <td>0.312900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8620</td>\n",
              "      <td>0.449600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8630</td>\n",
              "      <td>0.155500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8640</td>\n",
              "      <td>0.340400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>0.342800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8660</td>\n",
              "      <td>0.326800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8670</td>\n",
              "      <td>0.208800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8680</td>\n",
              "      <td>0.506500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8690</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.492400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8710</td>\n",
              "      <td>0.211200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8720</td>\n",
              "      <td>0.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8730</td>\n",
              "      <td>0.457800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8740</td>\n",
              "      <td>0.399900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>0.319100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8760</td>\n",
              "      <td>0.270600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8770</td>\n",
              "      <td>0.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8780</td>\n",
              "      <td>0.207100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8790</td>\n",
              "      <td>0.185000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.403600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8810</td>\n",
              "      <td>0.300500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8820</td>\n",
              "      <td>0.242300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8830</td>\n",
              "      <td>0.184900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8840</td>\n",
              "      <td>0.374600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>0.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8860</td>\n",
              "      <td>0.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8870</td>\n",
              "      <td>0.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8880</td>\n",
              "      <td>0.128500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8890</td>\n",
              "      <td>0.487200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8910</td>\n",
              "      <td>0.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8920</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8930</td>\n",
              "      <td>0.215800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8940</td>\n",
              "      <td>0.198900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>0.212600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8960</td>\n",
              "      <td>0.330200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8970</td>\n",
              "      <td>0.289200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8980</td>\n",
              "      <td>0.245800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8990</td>\n",
              "      <td>0.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.194600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9010</td>\n",
              "      <td>0.346300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9020</td>\n",
              "      <td>0.314600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9030</td>\n",
              "      <td>0.386900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9040</td>\n",
              "      <td>0.223300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>0.153900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9060</td>\n",
              "      <td>0.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9070</td>\n",
              "      <td>0.143800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9080</td>\n",
              "      <td>0.252600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9090</td>\n",
              "      <td>0.240400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.266700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9110</td>\n",
              "      <td>0.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9120</td>\n",
              "      <td>0.220800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9130</td>\n",
              "      <td>0.571300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9140</td>\n",
              "      <td>0.282700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>0.246800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9160</td>\n",
              "      <td>0.358500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9170</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9180</td>\n",
              "      <td>0.242000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9190</td>\n",
              "      <td>0.166300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.163400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9210</td>\n",
              "      <td>0.169600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9220</td>\n",
              "      <td>0.401200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9230</td>\n",
              "      <td>0.375600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9240</td>\n",
              "      <td>0.231500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9260</td>\n",
              "      <td>0.269800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9270</td>\n",
              "      <td>0.251800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9280</td>\n",
              "      <td>0.205600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9290</td>\n",
              "      <td>0.317500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.189600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9310</td>\n",
              "      <td>0.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9320</td>\n",
              "      <td>0.321100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9330</td>\n",
              "      <td>0.394700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9340</td>\n",
              "      <td>0.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>0.341400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9360</td>\n",
              "      <td>0.335900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9370</td>\n",
              "      <td>0.222900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 2363.01 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 02:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.63%\n",
            "Trainable parameters: 124647170\n",
            "GPU memory used: 1449.31 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store all results\n",
        "results = []\n"
      ],
      "metadata": {
        "id": "dbSv-Pjw2I3F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example after training a model\n",
        "technique_result = {\n",
        "    \"name\": \"Full Fine-tuning\",\n",
        "    \"accuracy\": eval_results[\"eval_accuracy\"],\n",
        "    \"training_time\": end - start,\n",
        "    \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    \"gpu_memory\": torch.cuda.max_memory_allocated() / 1024 ** 2  # in MB\n",
        "}\n",
        "\n",
        "results.append(technique_result)\n"
      ],
      "metadata": {
        "id": "3VePNLEp2Myc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LOra**"
      ],
      "metadata": {
        "id": "0Ze7d0dJ2rXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install peft\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGF0dtBsfxAZ",
        "outputId": "f8a5e3a2-35fb-4949-9c80-3b2c0b100495"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YZJB8VBrNRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA"
      ],
      "metadata": {
        "id": "q808zjVUIlzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from peft import get_peft_model, LoraConfig\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Define LoRA configuration with the correct task type\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Low-rank factor (hyperparameter)\n",
        "    lora_alpha=32,  # Scaling factor for LoRA layers\n",
        "    lora_dropout=0.1,  # Dropout probability for LoRA layers\n",
        "    task_type=\"SEQ_CLS\"  # Correct task type for sequence classification\n",
        ")\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "# 3. Apply LoRA to the model using PEFT (Low-Rank Adaptation)\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# 4. Define the Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/lora_finetune\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = torch.tensor(pred)\n",
        "    labels = torch.tensor(labels)\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    return {\"accuracy\": accuracy_score(labels.numpy(), pred.numpy())}\n",
        "\n",
        "# 6. Define Trainer for fine-tuning\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 7. Record training time\n",
        "start_time = time.time()\n",
        "\n",
        "# 8. Start training\n",
        "trainer.train()\n",
        "\n",
        "# 9. Record training time in seconds\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "accuracy = eval_results[\"eval_accuracy\"]\n",
        "trainable_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
        "gpu_memory_usage = torch.cuda.memory_allocated() / 1024 ** 2  # Convert to MB\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Number of trainable parameters: {trainable_params}\")\n",
        "print(f\"GPU memory usage: {gpu_memory_usage:.2f} MB\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e681c51bce93435192f32defccd6f76d",
            "7d38f373f76e4721962be0c853e70b0d",
            "5a9b9e71095f416e84a89bc6f429b318",
            "28013cab96c44804ac05bfc326efd096",
            "e5596b0ab5564f1b90d41c56e8138966",
            "bea32182286d4889bf30254ba89c4d68",
            "f0421e85af62487db431afcc36ca21b2",
            "d39e82a61b5541f898a5f62365c0f963",
            "e98028dc10634132a7da7e39b73b9871",
            "719510a7b6584608adafa6ec8f8bfd62",
            "c72e9479272c416fb5274c1f51f460a1",
            "becaa6a5497445d68531cb07105a0620",
            "f2bf29040c9a4fa888bda9eebd3c9f40",
            "7dfa902870854cc3bcea78602bd7e814",
            "9a24ea24b30c49249edd7521df2273f5",
            "593974955fb34d5e9aef987fca009b43",
            "216a290acec24497ac03e5bfc0732634",
            "52baa8e68d594710b2d2361877359105",
            "cb9ded8536974a8281b1713f0165dfef",
            "258c5c3319c449b59144a18c99723590",
            "345a31319e2949c7b29fff398b67890a",
            "0ec6184f16b64c02844fcc51b54b21cc"
          ]
        },
        "outputId": "9c50e1fc-78e7-455d-d337-9da965e5eb5b",
        "id": "68F9r2AMrNmA"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e681c51bce93435192f32defccd6f76d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "becaa6a5497445d68531cb07105a0620"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1125/1125 04:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.687700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.698700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.688600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.694500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.694700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.701100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.694400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.689700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.696300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.674000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.705100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.686300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.700400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.688300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.690900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.700200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.715400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.700200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.688900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.688600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.697500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.683500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.683400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.686300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.681800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.670800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.694500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.681400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.680500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.696200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.687600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.669000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.680600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.710900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.683600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.665400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.677300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.678800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.661300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.665400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.661300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.672100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.620400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.702300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.695800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.657900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.668800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.659000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.644700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.638900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.632900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.651300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.673300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.626200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.663900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.655200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.657100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.639600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.638100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.654500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.635600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.592500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.657700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.625900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.687900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.625400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.647900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.653200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.613900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.578700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.672000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.678300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.672100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.699200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.588700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.627200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.605200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.677200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.720800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.664000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 282.94 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 62.65%\n",
            "Number of trainable parameters: 887042\n",
            "GPU memory usage: 519.94 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "-Wk-zdpy2Qll"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapter Tuning (IA3)"
      ],
      "metadata": {
        "id": "cPfJ8xtQ3Y9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5ba_J7iOiy8",
        "outputId": "1ad54111-e595-41c7-b866-963b3dae33ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "N4I-q23GPa8Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0PE3rKoQIUu",
        "outputId": "4f0ffa59-f316-40b5-9a33-def7cf29650d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import IA3Config\n",
        "\n",
        "ia3_config = IA3Config(task_type=\"SEQ_CLS\")\n",
        "ia3_model = get_peft_model(model, ia3_config)\n"
      ],
      "metadata": {
        "id": "-myLGajtZyFE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "from peft import IA3Config, get_peft_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "# Apply IA3 adapter tuning\n",
        "ia3_config = IA3Config(task_type=\"SEQ_CLS\")\n",
        "ia3_model = get_peft_model(model, ia3_config)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/ia3_finetune\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        ")\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(p):\n",
        "    preds, labels = p\n",
        "    preds = torch.tensor(preds).argmax(dim=1)\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=ia3_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "eval_results = trainer.evaluate()\n",
        "accuracy = eval_results[\"eval_accuracy\"]\n",
        "trainable_params = sum(p.numel() for p in ia3_model.parameters() if p.requires_grad)\n",
        "gpu_memory_usage = torch.cuda.memory_allocated() / 1024 ** 2  # in MB\n",
        "\n",
        "# Results\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Trainable Parameters: {trainable_params}\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"GPU Memory Usage: {gpu_memory_usage:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M4YdzOZYRuF9",
        "outputId": "dad73c4d-f5f7-475d-995a-6e8f2b687a0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1125/1125 10:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.645200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.424900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.282500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.114100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.048100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.042800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.031100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "Trainable Parameters: 656642\n",
            "Training Time: 622.55 seconds\n",
            "GPU Memory Usage: 1001.99 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLoCCXzi4IEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example after training a model\n",
        "technique_result = {\n",
        "    \"name\": \"Adapter\",  # change for LoRA, QLoRA, Adapter\n",
        "    \"accuracy\": eval_results[\"eval_accuracy\"],\n",
        "    \"training_time\": end - start,\n",
        "    \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    \"gpu_memory\": torch.cuda.max_memory_allocated() / 1024 ** 2  # in MB\n",
        "}\n",
        "\n",
        "results.append(technique_result)\n"
      ],
      "metadata": {
        "id": "BOCXjPwL2Xwu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y4jIJPZie14",
        "outputId": "9e26ada5-2eb4-45a3-8e40-ea9352159fd4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QLORA"
      ],
      "metadata": {
        "id": "anGF6JywFm62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUB39VjQnx9e",
        "outputId": "0fd1e6b1-b50a-42a6-dabc-e456d0ca98c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers accelerate bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yuSkGq37JAot",
        "outputId": "eb05db10-3742-415a-a9fd-b09ad0678046"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load IMDb dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
        "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize, batched=True)\n",
        "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Quant config\n",
        "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "# Load model with 8-bit\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"prajjwal1/bert-tiny\",\n",
        "    num_labels=2,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# LoRA config\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "# Add LoRA adapters\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "\n",
        "# Training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    labels = eval_pred.label_ids\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554,
          "referenced_widgets": [
            "d9e1f9ffa46443ba970bc126ebd58246",
            "ac1c9ccb7d314fc9980acd01e313cc3a",
            "bd255724520c44f6b6ab286f66623ce5",
            "2e07cf9ac0414f04a6d74fb8332866dd",
            "34675123ac8248d18dc0e26e56180933",
            "cc2cd556e2514ddc86bf2746dd8b70df",
            "b9d4b7784b8142f2a8d299fee684880e",
            "7f62e9480ab9494ab6db58f4b324dbbb",
            "1de1e66e15b545f284d32ecb65423394",
            "2e7d4f247fe645bba7637c481e355505",
            "82750585759b498685d57bfefdfd7631"
          ]
        },
        "id": "X0lUhU4KoxZk",
        "outputId": "7111c03e-e856-44a2-cd2e-be54e0099b8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9e1f9ffa46443ba970bc126ebd58246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrabiyahumayon\u001b[0m (\u001b[33mrabiyahumayon-fas-tuning\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250425_155044-ovb5wxhr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabiyahumayon-fas-tuning/huggingface/runs/ovb5wxhr' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rabiyahumayon-fas-tuning/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rabiyahumayon-fas-tuning/huggingface' target=\"_blank\">https://wandb.ai/rabiyahumayon-fas-tuning/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rabiyahumayon-fas-tuning/huggingface/runs/ovb5wxhr' target=\"_blank\">https://wandb.ai/rabiyahumayon-fas-tuning/huggingface/runs/ovb5wxhr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1125/1125 00:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.343700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1125, training_loss=0.15275716145833335, metrics={'train_runtime': 66.4254, 'train_samples_per_second': 135.49, 'train_steps_per_second': 16.936, 'total_flos': 5834004480000.0, 'train_loss': 0.15275716145833335, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Track training time\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate on test set\n",
        "eval_result = trainer.evaluate()\n",
        "accuracy = eval_result[\"eval_accuracy\"] * 100\n",
        "\n",
        "# Count trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# GPU memory usage (in MB)\n",
        "gpu_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nAccuracy on test set: {accuracy:.2f}%\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Max GPU memory usage: {gpu_memory:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6zenQsoWqDCC",
        "outputId": "940d9e40-b75c-4ffb-f75d-8de3066e5876"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1125/1125 00:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on test set: 50.00%\n",
            "Trainable parameters: 8450\n",
            "Training time: 29.67 seconds\n",
            "Max GPU memory usage: 63.17 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_z7bmnwGCNSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Results from Full Fine-Tuning, LoRA, Adapter, QLoRA\n",
        "results = [\n",
        "      {\"name\": \"Full Fine-Tuning\", \"accuracy\": 0.88, \"training_time\": 2363.01, \"trainable_params\": 124647170, \"gpu_memory\": 1449.31 },\n",
        "    {\"name\": \"LoRA\", \"accuracy\": 0.66, \"training_time\": 614.61, \"trainable_params\": 887042, \"gpu_memory\": 519.94},\n",
        "    {\"name\": \"Adapter\", \"accuracy\": 0.80, \"training_time\": 600.55, \"trainable_params\": 656642, \"gpu_memory\": 1001.99},\n",
        "    {\"name\": \"QLoRA\", \"accuracy\": 0.50, \"training_time\": 32.34, \"trainable_params\": 85400, \"gpu_memory\": 63.17}\n",
        "]\n",
        "\n",
        "# Prepare data for bar chart plotting\n",
        "names = [technique[\"name\"] for technique in results]\n",
        "accuracies = [technique[\"accuracy\"] for technique in results]\n",
        "training_times = [technique[\"training_time\"] for technique in results]\n",
        "trainable_params = [technique[\"trainable_params\"] for technique in results]\n",
        "gpu_memory = [technique[\"gpu_memory\"] for technique in results]\n",
        "\n",
        "# Bar chart for Accuracy\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.barh(names, accuracies, color=\"skyblue\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "\n",
        "# Plot training time\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.barh(names, training_times, color=\"salmon\")\n",
        "plt.xlabel(\"Training Time (seconds)\")\n",
        "plt.title(\"Training Time Comparison\")\n",
        "\n",
        "# Plot number of trainable parameters\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.barh(names, trainable_params, color=\"lightgreen\")\n",
        "plt.xlabel(\"Number of Trainable Parameters\")\n",
        "plt.title(\"Trainable Parameters Comparison\")\n",
        "\n",
        "# Plot GPU memory usage\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.barh(names, gpu_memory, color=\"orange\")\n",
        "plt.xlabel(\"GPU Memory Usage (MB)\")\n",
        "plt.title(\"GPU Memory Usage Comparison\")\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "29d01e00-6328-4543-b107-cff1a5d270d7",
        "id": "oAJNAxwhCNy2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}